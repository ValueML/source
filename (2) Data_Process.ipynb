{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#We process the raw data retrieved from the providers\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to raw data\n",
    "IB_path = './../IB_API/IB/'\n",
    "AV_path = './../IB_API/AV/'\n",
    "#valuation dates\n",
    "valuation_dates = ['2019-12-31','2018-12-31','2017-12-31','2016-12-31','2015-12-31','2014-12-31','2013-12-31','2012-12-31','2011-12-31','2010-12-31','2009-12-31','2008-12-31','2007-12-31']\n",
    "#paths to saved data\n",
    "have_data_path ='./financials.txt'\n",
    "missing_data_path ='./financials_no_prices.txt'\n",
    "secret_salt=b\"secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse file and return data in list of dictionary items\n",
    "def parse_IB_data(item_path):\n",
    "    #collect the statement data\n",
    "    item_data = []    \n",
    "    symbol = item_path.split(\"/\")[-1]\n",
    "    #hash company symbol\n",
    "    symbol = hashlib.pbkdf2_hmac('sha256', symbol.encode('utf-8'), secret_salt, 100000).hex()[0:10]\n",
    "    ccy = item_path.split(\"/\")[-2]\n",
    "    with open(item_path) as fd:\n",
    "        soup = BeautifulSoup(fd.read(), \"xml\")\n",
    "        country =  soup.find('Exchange')['Country']\n",
    "        fiscal_periods = soup.find_all('FiscalPeriod')\n",
    "        for period in fiscal_periods:\n",
    "            #extract the data from within the statements\n",
    "            entry = {}\n",
    "            entry['Symbol'] = symbol\n",
    "            entry['Country'] = country\n",
    "            entry['Currency'] = ccy\n",
    "            entry['PeriodType'] = period['Type']\n",
    "            entry['PeriodEndDate'] = period['EndDate']\n",
    "            source = period.find('Source')\n",
    "            #deal with missing item attributes\n",
    "            if((source is None) or (source.has_attr('Date')==False)):\n",
    "                entry['SourceDate'] = valuation_dates[0]\n",
    "                entry['Source'] = 'Missing'  \n",
    "            else:\n",
    "                entry['SourceDate'] = source['Date']\n",
    "                entry['Source'] = source.string  \n",
    "            \n",
    "            auditoropinion = period.find('AuditorOpinion')\n",
    "            if(auditoropinion is None):\n",
    "                entry['AuditorOpinion']='None'\n",
    "            else:\n",
    "                entry['AuditorOpinion'] = auditoropinion['Code']\n",
    "            #Add all the line item data\n",
    "            lineitems = period.find_all('lineItem')\n",
    "            for line in lineitems:\n",
    "                entry[line['coaCode']]=float(line.string)\n",
    "            item_data.append(entry)\n",
    "\n",
    "    return item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_date(date_in):\n",
    "    date_out = (datetime.strptime(date_in, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    return date_out\n",
    "\n",
    "#parse the stock prices\n",
    "def parse_AV_data(AV_path,dates):\n",
    "    prices =[-1]*len(dates)\n",
    "    with open(AV_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    if 'Time Series (Daily)' in data:\n",
    "        for idx, item in enumerate(dates):\n",
    "            #we will take the average adjusted close price over the next 30 days \n",
    "            try_date = increment_date(item)\n",
    "            days = 30\n",
    "            price_matched = 0\n",
    "            while(days>0):\n",
    "                if(try_date in data['Time Series (Daily)']):\n",
    "                    prices[idx] = float(data['Time Series (Daily)'][try_date]['5. adjusted close'])\n",
    "                    price_matched +=1\n",
    "                days -=1\n",
    "                try_date = increment_date(try_date)\n",
    "            if(price_matched>0):\n",
    "                #take the average\n",
    "                prices[idx]=prices[idx]/price_matched\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step through each IB stock\n",
    "exclude=\"nodata\"\n",
    "have_data = []\n",
    "missing_data =[]\n",
    "cnt=0\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(IB_path,topdown=True):\n",
    "    dirnames[:] = [d for d in dirnames if d not in exclude]\n",
    "    if(len(dirnames)==0):\n",
    "        ccy=dirpath.split(\"/\")[-1]\n",
    "        for sym in filenames:\n",
    "            #check that we have stock data before continuing\n",
    "            av_search_file = os.path.join(AV_path,ccy,sym) + '_*'\n",
    "            av_file =''\n",
    "            for file in glob.glob(av_search_file):\n",
    "                av_file = file\n",
    "                break\n",
    "            if(av_file!=''):\n",
    "                #check valid contents\n",
    "                item_path = os.path.join(dirpath,sym)\n",
    "                financial_data = parse_IB_data(item_path)\n",
    "                \n",
    "                #get dates we want for stock prices\n",
    "                dates=[]\n",
    "                for entry in financial_data:\n",
    "                    dates.append(entry['SourceDate'])\n",
    "                #add on the valuation dates\n",
    "                dates += valuation_dates\n",
    "                stock_data = parse_AV_data(av_file,dates)\n",
    "                # get the valution points\n",
    "                stock_valuations = stock_data[len(financial_data):]\n",
    "                no_data =True\n",
    "                for idx, entry in enumerate(financial_data):                \n",
    "                    #add in the stock price at each valuation date\n",
    "                    if(stock_data[idx]>0):\n",
    "                        no_data=False\n",
    "                    for idxv, entryv in enumerate(stock_valuations):\n",
    "                        entry[valuation_dates[idxv]] = entryv\n",
    "                        if(entryv>0):\n",
    "                            no_data=False\n",
    "                if(no_data):\n",
    "                    #we keep the data without any financials just in case\n",
    "                    missing_data+=financial_data\n",
    "                else:\n",
    "                    #now we have all of the valuation data we include these in the financials data                \n",
    "                    have_data+=financial_data\n",
    "                cnt+=1\n",
    "                if(cnt%500==0):\n",
    "                    print(cnt)\n",
    "\n",
    "#save the processed data to disk\n",
    "financials_missing_df = pd.DataFrame(missing_data)\n",
    "financials_missing_df.to_csv(missing_data_path,sep='\\t')\n",
    "financials_df = pd.DataFrame(have_data)\n",
    "financials_df.to_csv(have_data_path,sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "p37workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
